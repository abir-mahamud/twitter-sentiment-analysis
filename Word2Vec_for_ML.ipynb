{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec for ML.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKeJmV7gXQSB"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz3osuSqXUBr",
        "outputId": "d4de278b-bc03-4c5d-b4b7-e4b57bd0f0eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "import sklearn\n",
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.naive_bayes import GaussianNB\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jvOR_qpcwri"
      },
      "source": [
        "**Load the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iWA1Fovc0PI",
        "outputId": "5e2153bc-24f4-454e-e8e6-f578922d959f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53vW7PKLdQ5c"
      },
      "source": [
        "# Load dataset\n",
        "def load_data():\n",
        "    data =pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Data/tweet_covid_processing_file.csv\", engine='python')\n",
        "    return data"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ihse48jZdUM3",
        "outputId": "da63080b-ca46-4c6a-9374-075f66538367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "tweet_df = load_data()\n",
        "tweet_df.head(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>label</th>\n",
              "      <th>clean_tweet</th>\n",
              "      <th>tweet_token</th>\n",
              "      <th>tweet_token_filtered</th>\n",
              "      <th>tweet_stemmed</th>\n",
              "      <th>tweet_lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>0</td>\n",
              "      <td>MeNyrbie  Phil Gahan  Chrisitv  and  and</td>\n",
              "      <td>['MeNyrbie', 'Phil', 'Gahan', 'Chrisitv', 'and...</td>\n",
              "      <td>['MeNyrbie', 'Phil', 'Gahan', 'Chrisitv']</td>\n",
              "      <td>menyrbi phil gahan chrisitv</td>\n",
              "      <td>MeNyrbie Phil Gahan Chrisitv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1</td>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>['advice', 'Talk', 'to', 'your', 'neighbours',...</td>\n",
              "      <td>['advice', 'Talk', 'neighbours', 'family', 'ex...</td>\n",
              "      <td>advic talk neighbour famili exchang phone numb...</td>\n",
              "      <td>advice Talk neighbour family exchange phone nu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1</td>\n",
              "      <td>Coronavirus Australia  Woolworths to give elde...</td>\n",
              "      <td>['Coronavirus', 'Australia', 'Woolworths', 'to...</td>\n",
              "      <td>['Coronavirus', 'Australia', 'Woolworths', 'gi...</td>\n",
              "      <td>coronaviru australia woolworth give elderli di...</td>\n",
              "      <td>Coronavirus Australia Woolworths give elderly ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1</td>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>['My', 'food', 'stock', 'is', 'not', 'the', 'o...</td>\n",
              "      <td>['My', 'food', 'stock', 'one', 'empty', 'PLEAS...</td>\n",
              "      <td>My food stock one empti pleas panic there will...</td>\n",
              "      <td>My food stock one empty PLEASE panic THERE WIL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "      <td>3</td>\n",
              "      <td>Me  ready to go at supermarket during the  COV...</td>\n",
              "      <td>['Me', 'ready', 'to', 'go', 'at', 'supermarket...</td>\n",
              "      <td>['Me', 'ready', 'go', 'supermarket', 'COVID', ...</td>\n",
              "      <td>Me readi go supermarket covid outbreak not I p...</td>\n",
              "      <td>Me ready go supermarket COVID outbreak Not I p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                   tweet_lemmatized\n",
              "0         0.0  ...                       MeNyrbie Phil Gahan Chrisitv\n",
              "1         1.0  ...  advice Talk neighbour family exchange phone nu...\n",
              "2         2.0  ...  Coronavirus Australia Woolworths give elderly ...\n",
              "3         3.0  ...  My food stock one empty PLEASE panic THERE WIL...\n",
              "4         4.0  ...  Me ready go supermarket COVID outbreak Not I p...\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hbv_gc7QdxDg"
      },
      "source": [
        "tweet_df.drop('Unnamed: 0',inplace=True,axis = 1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BASdg81Ud0yP",
        "outputId": "836078a9-25d8-46db-9d9a-d5b523f5403e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "tweet_df.head(5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>label</th>\n",
              "      <th>clean_tweet</th>\n",
              "      <th>tweet_token</th>\n",
              "      <th>tweet_token_filtered</th>\n",
              "      <th>tweet_stemmed</th>\n",
              "      <th>tweet_lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>0</td>\n",
              "      <td>MeNyrbie  Phil Gahan  Chrisitv  and  and</td>\n",
              "      <td>['MeNyrbie', 'Phil', 'Gahan', 'Chrisitv', 'and...</td>\n",
              "      <td>['MeNyrbie', 'Phil', 'Gahan', 'Chrisitv']</td>\n",
              "      <td>menyrbi phil gahan chrisitv</td>\n",
              "      <td>MeNyrbie Phil Gahan Chrisitv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1</td>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>['advice', 'Talk', 'to', 'your', 'neighbours',...</td>\n",
              "      <td>['advice', 'Talk', 'neighbours', 'family', 'ex...</td>\n",
              "      <td>advic talk neighbour famili exchang phone numb...</td>\n",
              "      <td>advice Talk neighbour family exchange phone nu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1</td>\n",
              "      <td>Coronavirus Australia  Woolworths to give elde...</td>\n",
              "      <td>['Coronavirus', 'Australia', 'Woolworths', 'to...</td>\n",
              "      <td>['Coronavirus', 'Australia', 'Woolworths', 'gi...</td>\n",
              "      <td>coronaviru australia woolworth give elderli di...</td>\n",
              "      <td>Coronavirus Australia Woolworths give elderly ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1</td>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>['My', 'food', 'stock', 'is', 'not', 'the', 'o...</td>\n",
              "      <td>['My', 'food', 'stock', 'one', 'empty', 'PLEAS...</td>\n",
              "      <td>My food stock one empti pleas panic there will...</td>\n",
              "      <td>My food stock one empty PLEASE panic THERE WIL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "      <td>3</td>\n",
              "      <td>Me  ready to go at supermarket during the  COV...</td>\n",
              "      <td>['Me', 'ready', 'to', 'go', 'at', 'supermarket...</td>\n",
              "      <td>['Me', 'ready', 'go', 'supermarket', 'COVID', ...</td>\n",
              "      <td>Me readi go supermarket covid outbreak not I p...</td>\n",
              "      <td>Me ready go supermarket COVID outbreak Not I p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       OriginalTweet  ...                                   tweet_lemmatized\n",
              "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...  ...                       MeNyrbie Phil Gahan Chrisitv\n",
              "1  advice Talk to your neighbours family to excha...  ...  advice Talk neighbour family exchange phone nu...\n",
              "2  Coronavirus Australia: Woolworths to give elde...  ...  Coronavirus Australia Woolworths give elderly ...\n",
              "3  My food stock is not the only one which is emp...  ...  My food stock one empty PLEASE panic THERE WIL...\n",
              "4  Me, ready to go at supermarket during the #COV...  ...  Me ready go supermarket COVID outbreak Not I p...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTqEZMsAeApo",
        "outputId": "b192c8ed-ecef-45c4-aa44-636acade385b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tweet_df.isnull().sum()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OriginalTweet            0\n",
              "Sentiment                2\n",
              "label                    2\n",
              "clean_tweet              2\n",
              "tweet_token              2\n",
              "tweet_token_filtered     2\n",
              "tweet_stemmed           16\n",
              "tweet_lemmatized        18\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r-ui9Q3eRFl"
      },
      "source": [
        "**Drop Null values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WT-DTmqeFmt"
      },
      "source": [
        "tweet_df= tweet_df.dropna()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r3nbZ8WeMIb",
        "outputId": "c1962c58-f9c6-4480-8826-ce8bb0247041",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tweet_df.isnull().sum()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OriginalTweet           0\n",
              "Sentiment               0\n",
              "label                   0\n",
              "clean_tweet             0\n",
              "tweet_token             0\n",
              "tweet_token_filtered    0\n",
              "tweet_stemmed           0\n",
              "tweet_lemmatized        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om3vl3fLlKj4",
        "outputId": "9a405cd1-fc67-468b-cdf7-e6e5f911071e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(tweet_df['tweet_lemmatized'])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41141"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve3O3nJ_nyL-",
        "outputId": "a027146e-7a69-4a0b-e134-9589d7fe9225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "tweet_df['tweet_lemmatized'][1]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'advice Talk neighbour family exchange phone number create contact list phone number neighbour school employer chemist GP set online shopping account po adequate supply regular med order'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DY_Ouyre32G"
      },
      "source": [
        "**Train the Word2Vec using gensim**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXDsrnVdlPPH",
        "outputId": "ed656f63-433d-4e5c-8206-3f799f586bd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Creating the model and setting values for the various parameters\n",
        "num_features = 200  # Word vector dimensionality\n",
        "min_word_count = 40 # Minimum word count\n",
        "num_workers = 4     # Number of parallel threads\n",
        "context = 10        # Context window size\n",
        "downsampling = 1e-3 # (0.001) Downsample setting for frequent words\n",
        "\n",
        "# Initializing the train model\n",
        "from gensim.models import word2vec\n",
        "print(\"Training model....\")\n",
        "model = word2vec.Word2Vec(sentences=tweet_df['tweet_lemmatized'],\\\n",
        "                          workers=num_workers,\\\n",
        "                          size=num_features,\\\n",
        "                          min_count=min_word_count,\\\n",
        "                          window=context,\n",
        "                          sample=downsampling)\n",
        "\n",
        "# To make the model memory efficient\n",
        "model.init_sims(replace=True)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVUZ6ndLnLjj",
        "outputId": "d3e5fdab-9182-469e-8100-90117bdc0a09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "words = list(model.wv.vocab)\n",
        "print('Here is the Vocabulary Size.. %d' % len(words))\n",
        "words"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Here is the Vocabulary Size.. 53\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['M',\n",
              " 'e',\n",
              " 'N',\n",
              " 'y',\n",
              " 'r',\n",
              " 'b',\n",
              " 'i',\n",
              " ' ',\n",
              " 'P',\n",
              " 'h',\n",
              " 'l',\n",
              " 'G',\n",
              " 'a',\n",
              " 'n',\n",
              " 'C',\n",
              " 's',\n",
              " 't',\n",
              " 'v',\n",
              " 'd',\n",
              " 'c',\n",
              " 'T',\n",
              " 'k',\n",
              " 'g',\n",
              " 'o',\n",
              " 'u',\n",
              " 'f',\n",
              " 'm',\n",
              " 'x',\n",
              " 'p',\n",
              " 'q',\n",
              " 'A',\n",
              " 'W',\n",
              " 'w',\n",
              " 'O',\n",
              " 'V',\n",
              " 'I',\n",
              " 'D',\n",
              " 'L',\n",
              " 'E',\n",
              " 'S',\n",
              " 'H',\n",
              " 'R',\n",
              " 'B',\n",
              " 'U',\n",
              " 'F',\n",
              " 'Y',\n",
              " 'z',\n",
              " 'j',\n",
              " 'Z',\n",
              " 'J',\n",
              " 'K',\n",
              " 'X',\n",
              " 'Q']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lka6FuSPnkTs",
        "outputId": "3de1dbe8-1432-46b4-e457-c0d61654a0c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.wv.most_similar(\"A\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('E', 0.8449580669403076),\n",
              " ('R', 0.7846043705940247),\n",
              " ('S', 0.7691285610198975),\n",
              " ('G', 0.7684274315834045),\n",
              " ('F', 0.7339881658554077),\n",
              " ('N', 0.722922682762146),\n",
              " ('P', 0.7191516160964966),\n",
              " ('L', 0.6974988579750061),\n",
              " ('M', 0.6945151090621948),\n",
              " ('H', 0.667276918888092)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWqO0h6sn7Sf",
        "outputId": "f5eae88d-97ad-4914-9dd2-85813e3e5f95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        }
      },
      "source": [
        "# Importing bokeh libraries for showing how words of similar context are grouped together\n",
        "import bokeh.plotting as bp\n",
        "from bokeh.models import HoverTool, BoxSelectTool\n",
        "from bokeh.plotting import figure, show, output_notebook\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "voc_size=3000\n",
        "#Defining the chart\n",
        "output_notebook()\n",
        "plot_chart = bp.figure(plot_width=700, plot_height=600, title=\"A map/plot of 3000 word vectors\",\n",
        "    tools=\"pan,wheel_zoom,box_zoom,reset,hover\",\n",
        "    x_axis_type=None, y_axis_type=None, min_border=1)\n",
        "\n",
        "#Extracting the list of word vectors, limiting to 1000, each is of 200 dimensions\n",
        "word_vectors = [model[w] for w in list(model.wv.vocab.keys())[:voc_size]]\n",
        "\n",
        "# Reducing dimensionality by converting the vectors to 2d vectors\n",
        "from sklearn.manifold import TSNE\n",
        "tsne_model = TSNE(n_components=2, verbose=1, random_state=0)\n",
        "tsne_w2v = tsne_model.fit_transform(word_vectors)\n",
        "\n",
        "# Storing data in a dataframe\n",
        "tsne_df = pd.DataFrame(tsne_w2v, columns=['x', 'y'])\n",
        "tsne_df['words'] = list(model.wv.vocab.keys())[:voc_size]\n",
        "\n",
        "# Corresponding word appears when you hover on the data point.\n",
        "plot_chart.scatter(x='x', y='y', source=tsne_df)\n",
        "hover = plot_chart.select(dict(type=HoverTool))\n",
        "hover.tooltips={\"word\": \"@words\"}\n",
        "show(plot_chart)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[t-SNE] Computing 52 nearest neighbors...\n",
            "[t-SNE] Indexed 53 samples in 0.000s...\n",
            "[t-SNE] Computed neighbors for 53 samples in 0.003s...\n",
            "[t-SNE] Computed conditional probabilities for sample 53 / 53\n",
            "[t-SNE] Mean sigma: 0.733003\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 47.658154\n",
            "[t-SNE] KL divergence after 1000 iterations: 0.351829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "(function(root) {\n",
              "  function now() {\n",
              "    return new Date();\n",
              "  }\n",
              "\n",
              "  var force = true;\n",
              "\n",
              "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
              "    root._bokeh_onload_callbacks = [];\n",
              "    root._bokeh_is_loading = undefined;\n",
              "  }\n",
              "\n",
              "  var JS_MIME_TYPE = 'application/javascript';\n",
              "  var HTML_MIME_TYPE = 'text/html';\n",
              "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
              "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
              "\n",
              "  /**\n",
              "   * Render data to the DOM node\n",
              "   */\n",
              "  function render(props, node) {\n",
              "    var script = document.createElement(\"script\");\n",
              "    node.appendChild(script);\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when an output is cleared or removed\n",
              "   */\n",
              "  function handleClearOutput(event, handle) {\n",
              "    var cell = handle.cell;\n",
              "\n",
              "    var id = cell.output_area._bokeh_element_id;\n",
              "    var server_id = cell.output_area._bokeh_server_id;\n",
              "    // Clean up Bokeh references\n",
              "    if (id != null && id in Bokeh.index) {\n",
              "      Bokeh.index[id].model.document.clear();\n",
              "      delete Bokeh.index[id];\n",
              "    }\n",
              "\n",
              "    if (server_id !== undefined) {\n",
              "      // Clean up Bokeh references\n",
              "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
              "      cell.notebook.kernel.execute(cmd, {\n",
              "        iopub: {\n",
              "          output: function(msg) {\n",
              "            var id = msg.content.text.trim();\n",
              "            if (id in Bokeh.index) {\n",
              "              Bokeh.index[id].model.document.clear();\n",
              "              delete Bokeh.index[id];\n",
              "            }\n",
              "          }\n",
              "        }\n",
              "      });\n",
              "      // Destroy server and session\n",
              "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
              "      cell.notebook.kernel.execute(cmd);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when a new output is added\n",
              "   */\n",
              "  function handleAddOutput(event, handle) {\n",
              "    var output_area = handle.output_area;\n",
              "    var output = handle.output;\n",
              "\n",
              "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
              "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
              "      return\n",
              "    }\n",
              "\n",
              "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
              "\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
              "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
              "      // store reference to embed id on output_area\n",
              "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
              "    }\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
              "      var bk_div = document.createElement(\"div\");\n",
              "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "      var script_attrs = bk_div.children[0].attributes;\n",
              "      for (var i = 0; i < script_attrs.length; i++) {\n",
              "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
              "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
              "      }\n",
              "      // store reference to server id on output_area\n",
              "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
              "    }\n",
              "  }\n",
              "\n",
              "  function register_renderer(events, OutputArea) {\n",
              "\n",
              "    function append_mime(data, metadata, element) {\n",
              "      // create a DOM node to render to\n",
              "      var toinsert = this.create_output_subarea(\n",
              "        metadata,\n",
              "        CLASS_NAME,\n",
              "        EXEC_MIME_TYPE\n",
              "      );\n",
              "      this.keyboard_manager.register_events(toinsert);\n",
              "      // Render to node\n",
              "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
              "      render(props, toinsert[toinsert.length - 1]);\n",
              "      element.append(toinsert);\n",
              "      return toinsert\n",
              "    }\n",
              "\n",
              "    /* Handle when an output is cleared or removed */\n",
              "    events.on('clear_output.CodeCell', handleClearOutput);\n",
              "    events.on('delete.Cell', handleClearOutput);\n",
              "\n",
              "    /* Handle when a new output is added */\n",
              "    events.on('output_added.OutputArea', handleAddOutput);\n",
              "\n",
              "    /**\n",
              "     * Register the mime type and append_mime function with output_area\n",
              "     */\n",
              "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
              "      /* Is output safe? */\n",
              "      safe: true,\n",
              "      /* Index of renderer in `output_area.display_order` */\n",
              "      index: 0\n",
              "    });\n",
              "  }\n",
              "\n",
              "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
              "  if (root.Jupyter !== undefined) {\n",
              "    var events = require('base/js/events');\n",
              "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
              "\n",
              "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
              "      register_renderer(events, OutputArea);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  \n",
              "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
              "    root._bokeh_timeout = Date.now() + 5000;\n",
              "    root._bokeh_failed_load = false;\n",
              "  }\n",
              "\n",
              "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
              "     \"<div style='background-color: #fdd'>\\n\"+\n",
              "     \"<p>\\n\"+\n",
              "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
              "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
              "     \"</p>\\n\"+\n",
              "     \"<ul>\\n\"+\n",
              "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
              "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
              "     \"</ul>\\n\"+\n",
              "     \"<code>\\n\"+\n",
              "     \"from bokeh.resources import INLINE\\n\"+\n",
              "     \"output_notebook(resources=INLINE)\\n\"+\n",
              "     \"</code>\\n\"+\n",
              "     \"</div>\"}};\n",
              "\n",
              "  function display_loaded() {\n",
              "    var el = document.getElementById(null);\n",
              "    if (el != null) {\n",
              "      el.textContent = \"BokehJS is loading...\";\n",
              "    }\n",
              "    if (root.Bokeh !== undefined) {\n",
              "      if (el != null) {\n",
              "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
              "      }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(display_loaded, 100)\n",
              "    }\n",
              "  }\n",
              "\n",
              "\n",
              "  function run_callbacks() {\n",
              "    try {\n",
              "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
              "        if (callback != null)\n",
              "          callback();\n",
              "      });\n",
              "    } finally {\n",
              "      delete root._bokeh_onload_callbacks\n",
              "    }\n",
              "    console.debug(\"Bokeh: all callbacks have finished\");\n",
              "  }\n",
              "\n",
              "  function load_libs(css_urls, js_urls, callback) {\n",
              "    if (css_urls == null) css_urls = [];\n",
              "    if (js_urls == null) js_urls = [];\n",
              "\n",
              "    root._bokeh_onload_callbacks.push(callback);\n",
              "    if (root._bokeh_is_loading > 0) {\n",
              "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
              "      return null;\n",
              "    }\n",
              "    if (js_urls == null || js_urls.length === 0) {\n",
              "      run_callbacks();\n",
              "      return null;\n",
              "    }\n",
              "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
              "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
              "\n",
              "    function on_load() {\n",
              "      root._bokeh_is_loading--;\n",
              "      if (root._bokeh_is_loading === 0) {\n",
              "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
              "        run_callbacks()\n",
              "      }\n",
              "    }\n",
              "\n",
              "    function on_error() {\n",
              "      console.error(\"failed to load \" + url);\n",
              "    }\n",
              "\n",
              "    for (var i = 0; i < css_urls.length; i++) {\n",
              "      var url = css_urls[i];\n",
              "      const element = document.createElement(\"link\");\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.rel = \"stylesheet\";\n",
              "      element.type = \"text/css\";\n",
              "      element.href = url;\n",
              "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
              "      document.body.appendChild(element);\n",
              "    }\n",
              "\n",
              "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\": \"kLr4fYcqcSpbuI95brIH3vnnYCquzzSxHPU6XGQCIkQRGJwhg0StNbj1eegrHs12\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\": \"xIGPmVtaOm+z0BqfSOMn4lOR6ciex448GIKG4eE61LsAvmGj48XcMQZtKcE/UXZe\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\": \"Dc9u1wF/0zApGIWoBbH77iWEHtdmkuYWG839Uzmv8y8yBLXebjO9ZnERsde5Ln/P\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\": \"cT9JaBz7GiRXdENrJLZNSC6eMNF3nh3fa5fTF51Svp+ukxPdwcU5kGXGPBgDCa2j\"};\n",
              "\n",
              "    for (var i = 0; i < js_urls.length; i++) {\n",
              "      var url = js_urls[i];\n",
              "      var element = document.createElement('script');\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.async = false;\n",
              "      element.src = url;\n",
              "      if (url in hashes) {\n",
              "        element.crossOrigin = \"anonymous\";\n",
              "        element.integrity = \"sha384-\" + hashes[url];\n",
              "      }\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "  };\n",
              "\n",
              "  function inject_raw_css(css) {\n",
              "    const element = document.createElement(\"style\");\n",
              "    element.appendChild(document.createTextNode(css));\n",
              "    document.body.appendChild(element);\n",
              "  }\n",
              "\n",
              "  \n",
              "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\"];\n",
              "  var css_urls = [];\n",
              "  \n",
              "\n",
              "  var inline_js = [\n",
              "    function(Bokeh) {\n",
              "      Bokeh.set_log_level(\"info\");\n",
              "    },\n",
              "    function(Bokeh) {\n",
              "    \n",
              "    \n",
              "    }\n",
              "  ];\n",
              "\n",
              "  function run_inline_js() {\n",
              "    \n",
              "    if (root.Bokeh !== undefined || force === true) {\n",
              "      \n",
              "    for (var i = 0; i < inline_js.length; i++) {\n",
              "      inline_js[i].call(root, root.Bokeh);\n",
              "    }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(run_inline_js, 100);\n",
              "    } else if (!root._bokeh_failed_load) {\n",
              "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
              "      root._bokeh_failed_load = true;\n",
              "    } else if (force !== true) {\n",
              "      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
              "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
              "    }\n",
              "\n",
              "  }\n",
              "\n",
              "  if (root._bokeh_is_loading === 0) {\n",
              "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
              "    run_inline_js();\n",
              "  } else {\n",
              "    load_libs(css_urls, js_urls, function() {\n",
              "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
              "      run_inline_js();\n",
              "    });\n",
              "  }\n",
              "}(window));"
            ],
            "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\": \"kLr4fYcqcSpbuI95brIH3vnnYCquzzSxHPU6XGQCIkQRGJwhg0StNbj1eegrHs12\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\": \"xIGPmVtaOm+z0BqfSOMn4lOR6ciex448GIKG4eE61LsAvmGj48XcMQZtKcE/UXZe\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\": \"Dc9u1wF/0zApGIWoBbH77iWEHtdmkuYWG839Uzmv8y8yBLXebjO9ZnERsde5Ln/P\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\": \"cT9JaBz7GiRXdENrJLZNSC6eMNF3nh3fa5fTF51Svp+ukxPdwcU5kGXGPBgDCa2j\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "  <div class=\"bk-root\" id=\"79a75254-cadb-4fb2-8799-966913e9828a\" data-root-id=\"1196\"></div>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "(function(root) {\n",
              "  function embed_document(root) {\n",
              "    \n",
              "  var docs_json = {\"d18530ac-7d40-4323-90b6-4826d0fe4a55\":{\"roots\":{\"references\":[{\"attributes\":{\"min_border\":1,\"plot_width\":700,\"renderers\":[{\"id\":\"1223\"}],\"title\":{\"id\":\"1197\"},\"toolbar\":{\"id\":\"1213\"},\"x_range\":{\"id\":\"1199\"},\"x_scale\":{\"id\":\"1203\"},\"y_range\":{\"id\":\"1201\"},\"y_scale\":{\"id\":\"1205\"}},\"id\":\"1196\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1199\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1208\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"text\":\"A map/plot of 3000 word vectors\"},\"id\":\"1197\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1205\",\"type\":\"LinearScale\"},{\"attributes\":{\"overlay\":{\"id\":\"1212\"}},\"id\":\"1209\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1203\",\"type\":\"LinearScale\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1207\"},{\"id\":\"1208\"},{\"id\":\"1209\"},{\"id\":\"1210\"},{\"id\":\"1211\"}]},\"id\":\"1213\",\"type\":\"Toolbar\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"word\",\"@words\"]]},\"id\":\"1211\",\"type\":\"HoverTool\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1221\",\"type\":\"Scatter\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1222\",\"type\":\"Scatter\"},{\"attributes\":{\"source\":{\"id\":\"1219\"}},\"id\":\"1224\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1210\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1201\",\"type\":\"DataRange1d\"},{\"attributes\":{\"data_source\":{\"id\":\"1219\"},\"glyph\":{\"id\":\"1221\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1222\"},\"selection_glyph\":null,\"view\":{\"id\":\"1224\"}},\"id\":\"1223\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1227\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1228\",\"type\":\"Selection\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1212\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"data\":{\"index\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52],\"words\":[\"M\",\"e\",\"N\",\"y\",\"r\",\"b\",\"i\",\" \",\"P\",\"h\",\"l\",\"G\",\"a\",\"n\",\"C\",\"s\",\"t\",\"v\",\"d\",\"c\",\"T\",\"k\",\"g\",\"o\",\"u\",\"f\",\"m\",\"x\",\"p\",\"q\",\"A\",\"W\",\"w\",\"O\",\"V\",\"I\",\"D\",\"L\",\"E\",\"S\",\"H\",\"R\",\"B\",\"U\",\"F\",\"Y\",\"z\",\"j\",\"Z\",\"J\",\"K\",\"X\",\"Q\"],\"x\":{\"__ndarray__\":\"PLQswi4z+0HzahTCnP5hQtNGZUImFxFC9OmBQj3S0kHeMJ3BXCWnQagEIULZc8PBxTK8QS1eiEKsjbrBobs+Qsx5P0IkD0FCtLBaQu/6a0KtjlrC7V/vQbZGQkKgSohCGw2ZQkUwQEIXfBhCYNKjQVxtIUKfOf1BhYAJwoLRYsGTex1C70kGwpbHAcGER2/BtcS/wVit8cHkTjDCTJMjwrQMWcJvowbCSqOKwXYa3sGmsdbB28E7whO04UDHID5B8xHxwPXdGcEnK0/Co30fwvF+wcE=\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[53]},\"y\":{\"__ndarray__\":\"eH8IQHYmO0A/c3PBBciAQLwfl8HzL2ZBFpKgwHd/tUG4NpjBYHMiwEOPnEBqf1E9+dAjQRYj0EAYmMZB+cljwVHY8L64wdzBcJLxwBOMb0HskDDBuhwCwWPKpUEZFojBGNy4wP7pKEElpnvBXoSSwfGMrsCvltPBqCSvwGXWJkGAguBBao3YQWxQ8MFhMutBlVYOQmZTucHddPbAh/VIQfW+mD9tnWxAI6newBsKQkGa4zfBCoGawSZ9MkDwfptBQXhKwfwFd79YVWNBTznmwealB8I=\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[53]}},\"selected\":{\"id\":\"1228\"},\"selection_policy\":{\"id\":\"1227\"}},\"id\":\"1219\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1207\",\"type\":\"PanTool\"}],\"root_ids\":[\"1196\"]},\"title\":\"Bokeh Application\",\"version\":\"2.1.1\"}};\n",
              "  var render_items = [{\"docid\":\"d18530ac-7d40-4323-90b6-4826d0fe4a55\",\"root_ids\":[\"1196\"],\"roots\":{\"1196\":\"79a75254-cadb-4fb2-8799-966913e9828a\"}}];\n",
              "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "\n",
              "  }\n",
              "  if (root.Bokeh !== undefined) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    var attempts = 0;\n",
              "    var timer = setInterval(function(root) {\n",
              "      if (root.Bokeh !== undefined) {\n",
              "        clearInterval(timer);\n",
              "        embed_document(root);\n",
              "      } else {\n",
              "        attempts++;\n",
              "        if (attempts > 100) {\n",
              "          clearInterval(timer);\n",
              "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
              "        }\n",
              "      }\n",
              "    }, 10, root)\n",
              "  }\n",
              "})(window);"
            ],
            "application/vnd.bokehjs_exec.v0+json": ""
          },
          "metadata": {
            "tags": [],
            "application/vnd.bokehjs_exec.v0+json": {
              "id": "1196"
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7FDteJBoTTQ"
      },
      "source": [
        "\"\"\"import numpy as np\n",
        "embedding_matrix = np.zeros((len(model.wv.vocab) + 1, 300))\n",
        "for i, vec in enumerate(model.wv.vectors):\n",
        "    embedding_matrix[i] = vec\"\"\"\n",
        "import numpy as np \n",
        "#Build word vector set by using the average value of all word vectors , then scale\n",
        "def buildWordVector(text, size):\n",
        "    vec = np.zeros(size).reshape((1, size)) #As word vectors are of zero length size value(i.e 300) \n",
        "    count = 0 # no. of words with a valid vector in the sentence/review\n",
        "    for word in text: #for each word in a sentence/review\n",
        "        try:\n",
        "            vec += model[word].reshape((1, size))\n",
        "            count += 1.\n",
        "        except KeyError:\n",
        "            continue\n",
        "    if count != 0:\n",
        "        vec /= count\n",
        "    return vec"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU8_Aw5Joaz0",
        "outputId": "84ffb4f3-e6a2-4105-c9c2-44cf0f7e7a08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.preprocessing import scale\n",
        "vecs = np.concatenate([buildWordVector(z, Size) for z in tweet_df['tweet_lemmatized']])\n",
        "#print(\"Before Scaling:\",vecs[1:2])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S70u09bq94-",
        "outputId": "4c7da2ab-14a4-43a6-b1df-94fd63f2d56e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Dimension of vector :\",vecs.shape)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimension of vector : (41141, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW1x4ZnbrRAv",
        "outputId": "24de7bd5-c88f-429e-aade-e4a1c28102dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vecs"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.01455165,  0.0375589 ,  0.02465053, ..., -0.00917693,\n",
              "         0.00718173, -0.00288007],\n",
              "       [-0.00586966,  0.06729438,  0.05745566, ..., -0.01253773,\n",
              "        -0.00488357, -0.01230897],\n",
              "       [-0.0049429 ,  0.05172257,  0.05570694, ...,  0.00800712,\n",
              "        -0.00479591, -0.01645128],\n",
              "       ...,\n",
              "       [-0.0048766 ,  0.07091722,  0.05119136, ..., -0.0058158 ,\n",
              "        -0.00689215, -0.01608963],\n",
              "       [ 0.00090541,  0.0433938 ,  0.06198582, ...,  0.01303102,\n",
              "        -0.01470601, -0.01638389],\n",
              "       [-0.00147304,  0.0571238 ,  0.04876145, ..., -0.01331844,\n",
              "        -0.00956458, -0.00443603]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0All0XSrUGu"
      },
      "source": [
        "import sklearn\n",
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXESNMYLrt9P",
        "outputId": "b8771246-d735-4778-a87a-dab3d9fcc94f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install opentsne"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opentsne\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/3e/e2d8bffa1524b5b108e3d5b00d93b458d500b5c65df7fd50b7490d38c6f8/openTSNE-0.4.4-cp36-cp36m-manylinux1_x86_64.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 969kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from opentsne) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from opentsne) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.6/dist-packages (from opentsne) (1.18.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->opentsne) (0.17.0)\n",
            "Installing collected packages: opentsne\n",
            "Successfully installed opentsne-0.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Imix-KsraB1"
      },
      "source": [
        "from openTSNE import TSNE\n",
        "\n",
        "tsne_model_v2 = tsne = TSNE(\n",
        "    n_components=2, perplexity=30, learning_rate=200,\n",
        "    n_jobs=4, initialization=\"pca\", metric=\"euclidean\",\n",
        "    early_exaggeration_iter=250, early_exaggeration=12, n_iter=750,\n",
        "    neighbors=\"exact\", negative_gradient_method=\"bh\")\n",
        "\n",
        "vecs_v1 = tsne_model_v2.fit(vecs)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smRtxHnZ0Gin",
        "outputId": "d97d7183-abed-401a-970a-d5a53313981b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vecs_v1.shape"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41141, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrrIbZMS0PnK"
      },
      "source": [
        "\n",
        "Y_word2vec = tweet_df['label']"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJWqBWmO0opn",
        "outputId": "d735383a-0070-48ea-d21f-147441c9a1c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "smk_tiagram = SMOTETomek(random_state=42)\n",
        "X_vec_v1,Y_vec_v1=smk_tiagram.fit_sample(vecs_v1,Y_word2vec)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1daqxTm60wvY",
        "outputId": "db870dbb-437f-4a99-dc35-1b533a6795fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from collections import Counter\n",
        "print('Original dataset shape {}'.format(Counter(Y_word2vec)))\n",
        "print('Resampled dataset shape {}'.format(Counter(Y_vec_v1)))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original dataset shape Counter({'1': 11422, '4': 9917, '0': 7697, '2': 6624, '3': 5481})\n",
            "Resampled dataset shape Counter({'3': 8360, '2': 8163, '0': 8030, '4': 7293, '1': 6944})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msOI5Kwn1G4G"
      },
      "source": [
        "# let's see how well our model perform on this new data\n",
        "x_train,x_test,y_train,y_test = train_test_split(X_vec_v1,Y_vec_v1,test_size = 0.30, random_state= True)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zpN51hu1XMt"
      },
      "source": [
        "**Made the classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOAoo0_91ahE"
      },
      "source": [
        "#We shall experiment common traditional machine learning algorithms in this section. We have done already for extracting the features using Word2Vec lirary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aul_0GpW1p83",
        "outputId": "06176981-3852-4f13-8e88-16e3eb52ad7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Decission Tree Classifier\n",
        "decession_tree = DecisionTreeClassifier()\n",
        "decession_tree.fit(x_train,y_train)\n",
        "y_pred_decession_tree = decession_tree.predict(x_test)\n",
        "print(\"Decission Tree Classifier\")\n",
        "print(classification_report(y_test, y_pred_decession_tree))\n",
        "\n",
        "# Random Forest  Classifier\n",
        "random_forest = RandomForestClassifier()\n",
        "random_forest.fit(x_train,y_train)\n",
        "y_pred_random_forest = random_forest.predict(x_test)\n",
        "print(\"Random Forest  Classifier\")\n",
        "print(classification_report(y_test, y_pred_random_forest))\n",
        "\n",
        "\n",
        "# KNN  Algo\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "knn_classifier.fit(x_train,y_train)\n",
        "y_pred_knn_classifier = knn_classifier.predict(x_test)\n",
        "print(\"KNN  Algo\")\n",
        "print(classification_report(y_test, y_pred_knn_classifier))\n",
        "\n",
        "\n",
        "# Multinomial Naive Bias\n",
        "mulNB = GaussianNB()\n",
        "mulNB.fit(x_train,y_train)\n",
        "y_pred_mulNB = mulNB.predict(x_test)\n",
        "print(\"Gaussian Naive Bias\")\n",
        "print(classification_report(y_test, y_pred_mulNB))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decission Tree Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.50      0.49      2376\n",
            "           1       0.34      0.30      0.32      2108\n",
            "           2       0.47      0.48      0.48      2403\n",
            "           3       0.51      0.54      0.53      2525\n",
            "           4       0.38      0.37      0.37      2225\n",
            "\n",
            "    accuracy                           0.44     11637\n",
            "   macro avg       0.44      0.44      0.44     11637\n",
            "weighted avg       0.44      0.44      0.44     11637\n",
            "\n",
            "Random Forest  Classifier\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.58      0.56      2376\n",
            "           1       0.37      0.30      0.33      2108\n",
            "           2       0.51      0.56      0.53      2403\n",
            "           3       0.54      0.61      0.57      2525\n",
            "           4       0.45      0.39      0.41      2225\n",
            "\n",
            "    accuracy                           0.49     11637\n",
            "   macro avg       0.48      0.48      0.48     11637\n",
            "weighted avg       0.48      0.49      0.49     11637\n",
            "\n",
            "KNN  Algo\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.57      0.49      2376\n",
            "           1       0.27      0.23      0.25      2108\n",
            "           2       0.41      0.48      0.44      2403\n",
            "           3       0.47      0.49      0.48      2525\n",
            "           4       0.37      0.22      0.27      2225\n",
            "\n",
            "    accuracy                           0.41     11637\n",
            "   macro avg       0.39      0.40      0.39     11637\n",
            "weighted avg       0.40      0.41      0.39     11637\n",
            "\n",
            "Gaussian Naive Bias\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.54      0.39      2376\n",
            "           1       0.00      0.00      0.00      2108\n",
            "           2       0.27      0.50      0.35      2403\n",
            "           3       0.27      0.30      0.28      2525\n",
            "           4       0.00      0.00      0.00      2225\n",
            "\n",
            "    accuracy                           0.28     11637\n",
            "   macro avg       0.17      0.27      0.20     11637\n",
            "weighted avg       0.17      0.28      0.21     11637\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-FIzvqA6LGG",
        "outputId": "e258adb4-6c7e-4f3c-a57f-4afc57e81259",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Gradient bossting\n",
        "gradient_bossting = GradientBoostingClassifier(random_state=3)\n",
        "gradient_bossting.fit(x_train,y_train)\n",
        "y_pred_gradientbossting = gradient_bossting.predict(x_test)\n",
        "print(\"GradientBosting  Algo\")\n",
        "print(classification_report(y_test, y_pred_gradientbossting))\n",
        "\n",
        "\n",
        "# SVM\n",
        "svm_class = svm.SVC(kernel='poly')\n",
        "svm_class.fit(x_train,y_train)\n",
        "y_pred_svm = svm_class.predict(x_test)\n",
        "print(\"SVM  Algo\")\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "\n",
        "\n",
        "# Logistic Regressor\n",
        "logis_reg =LogisticRegression()\n",
        "logis_reg.fit(x_train,y_train)\n",
        "y_pred_log = logis_reg.predict(x_test)\n",
        "print(\"Logistic Reg  Algo\")\n",
        "print(classification_report(y_test, y_pred_log))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GradientBosting  Algo\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.37      0.45      0.41      2376\n",
            "           1       0.28      0.02      0.03      2108\n",
            "           2       0.27      0.49      0.35      2403\n",
            "           3       0.28      0.44      0.34      2525\n",
            "           4       0.31      0.04      0.07      2225\n",
            "\n",
            "    accuracy                           0.30     11637\n",
            "   macro avg       0.30      0.29      0.24     11637\n",
            "weighted avg       0.30      0.30      0.25     11637\n",
            "\n",
            "SVM  Algo\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.40      0.37      2376\n",
            "           1       0.00      0.00      0.00      2108\n",
            "           2       0.27      0.42      0.33      2403\n",
            "           3       0.24      0.48      0.32      2525\n",
            "           4       0.00      0.00      0.00      2225\n",
            "\n",
            "    accuracy                           0.27     11637\n",
            "   macro avg       0.17      0.26      0.20     11637\n",
            "weighted avg       0.18      0.27      0.21     11637\n",
            "\n",
            "Logistic Reg  Algo\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.57      0.39      2376\n",
            "           1       0.00      0.00      0.00      2108\n",
            "           2       0.27      0.49      0.34      2403\n",
            "           3       0.26      0.28      0.27      2525\n",
            "           4       0.00      0.00      0.00      2225\n",
            "\n",
            "    accuracy                           0.28     11637\n",
            "   macro avg       0.17      0.27      0.20     11637\n",
            "weighted avg       0.17      0.28      0.21     11637\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}